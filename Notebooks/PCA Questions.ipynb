{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM on Digits Data Set\n",
    "\n",
    "* Load in the digits dataset\n",
    "* divide all the features by 16\n",
    "* make the labels binary for even or odd\n",
    "* Split into a training and testing set\n",
    "* Build a SVM. What is the accuracy on the test set?\n",
    "* Build an SVM tuning the C and gamma parameters. Try multiples of 10 from 0.001 to 100\n",
    "* Did tuning the parameters help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM on Digits Data Set\n",
    "\n",
    "* Now do the non-binary case. Do not split into an even and odd set\n",
    "* divide all the features by 16\n",
    "* Split into a training and testing set\n",
    "* Build a SVM. What is the accuracy on the test set?\n",
    "* Build an SVM tuning the C and gamma parameters. Try multiples of 10 from 0.001 to 100\n",
    "* Did tuning the parameters help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "* Create an (x,y) dataset where x is 0 to 10 by 0.1 and y is x plus a random normal error\n",
    "* Create a scatter plot of the data\n",
    "* Perform PCA on the (x,y) data\n",
    "    1. You'll have to use sklearn PCA()\n",
    "    2. Note you need to fit the data and then transform the data. Use .fit() then .transform methods\n",
    "* What is the explained variance of the principal components? Look at the attributes documentation under pca on the sklearn site\n",
    "* Create a scatter plot of the data in the new space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on the Digits Data\n",
    "\n",
    "* Load in the digits data\n",
    "* Fit and transform the digits data\n",
    "* Create a scatterplot of the first two PCs colored by the digit type\n",
    "* What is the explained variance of the components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on the Iris Data\n",
    "\n",
    "* Load the iris data\n",
    "* run pca on the data\n",
    "* Create a scatter plot of the first two PCs colored by class\n",
    "* What is the explained variance?\n",
    "* Create a bar chart of the explained variance of each PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear PCA, Kernel PCA\n",
    "\n",
    "* Load in sklearn's dataset load teh make_moons function\n",
    "* Use X, y = make_moons(n_samples=100, random_state=123) to create a data set\n",
    "* Create a scatter pot of this data colored by y.\n",
    "* Run PCA on the data set\n",
    "* Plot the first two PCs colored by y\n",
    "* Plot the first PC colored by y\n",
    "* What is the explained variance?\n",
    "\n",
    "* Run kernel PCA on the data set\n",
    "* Plot the first two kernel PCs colored by y\n",
    "* Plot the first kernel PC colored by y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM and Facial Recognition\n",
    "\n",
    "* Load in the sklearn faces dataset. \n",
    "    1. from sklearn.datasets import fetch_lfw_people\n",
    "    2. lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "* Using the shape method on the dataset store the returned values to n_samples, h, w\n",
    "* Set X to the faces data and let n_features = X.shape[1], \n",
    "* set\n",
    "    1. y to the targets\n",
    "    2. target_names to the target_names\n",
    "    3. n_classes = target_names.shape[0]\n",
    "* What's the dataset size: number of features, samples, classes?\n",
    "* Split into a train and test set where test_size=0.25)\n",
    "* Let n_components = 150\n",
    "* Perform PCA on the dataset. Use the RandomizedPCA() version, this is for speed. Use parameters n_components=n_components and whiten=True\n",
    "* create eigenfaces using: eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "* Transform the training and test set\n",
    "* Build a kernel SVM with the rbf kernel where you use grid search to tune C and gamma\n",
    "* Use the best estimator from grid search and predict on the test test\n",
    "* Print out the classification report and confusion matrix\n",
    "* Use the two below functions to print the faces\n",
    "    1. prediction_titles = [title(y_pred, y_test, target_names, i)for i in range(y_pred.shape[0])]\n",
    "    2. plot_gallery(X_test, prediction_titles, h, w)\n",
    "    3. eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "    4. plot_gallery(eigenfaces, eigenface_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Qualitative evaluation of the predictions using matplotlib\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
